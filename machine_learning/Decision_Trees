import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_excel(r"D:\THB\Masterarbeit\scrapy_\immoscout\immoscout\dataset\5_Machine Learning\data.xlsx")

# # Splitting the data into training and testing
from sklearn.model_selection import train_test_split
#Add the target
X = df.drop(['price'], axis=1)
y = df['price']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)

#print out the shape of the training and testing set
print(f"Shape X_train: {X_train.shape}, Shape y_train: {y_train.shape}")
print(f"Shape X_test: {X_test.shape}, Shape y_test: {y_test.shape}")

# # Decision Trees Training Set

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np
#Fit Regression Model

# Step 1: Create an instance of DecisionTreeRegressor and set hyperparameters
dt_regressor = DecisionTreeRegressor(criterion = "squared_error", splitter = 'best', max_depth = 885, min_samples_split = 5,
                                     min_samples_leaf = 7, max_features = 9, random_state = 42)

# Step 2: Fit the model to the training data
dt_regressor.fit(X_train, y_train)

# Step 3: Make predictions on the test data
y_pred = dt_regressor.predict(X_train)

#Results
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Step 4: Evaluate the model's performance
dt_r2_train = r2_score(y_train, y_pred)
dt_mse_train = mean_squared_error(y_train, y_pred)
dt_rmse_train = np.sqrt(dt_mse_train)
dt_mae_train = mean_absolute_error(y_train, y_pred)

# Print the results
print("DT Training Set Results:")
print("R-squared (R2):", dt_r2_train)
print("Mean Squared Error (MSE):", dt_mse_train)
print("Root Mean Squared Error (RMSE):", dt_rmse_train)
print("Mean Absolute Error (MAE): ", dt_mae_train)

import matplotlib.pyplot as plt

# Assuming you have y_train and y_pred from your model
# If not, replace them with the correct variables

# Plot the predicted vs actual values
plt.scatter(y_train, y_pred, alpha=0.5)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], color="red")  # Plotting the perfect prediction line
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Predicted vs. Actual Values")
plt.grid(True, linestyle='--', alpha=0.7)

# Show the plot
plt.show()

import matplotlib.pyplot as plt

# Calculate residuals and variance of residuals
residuals = y_train - y_pred
residual_variance = residuals**2

# Create a scatter plot
plt.scatter(y_pred, residual_variance)
plt.xlabel('Predicted Values')
plt.ylabel('Variance of Residuals')
plt.title('Variance of Residuals vs. Predicted Values')
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

import matplotlib.pyplot as plt

# Calculate residuals
residuals = y_train - y_pred

# Create a scatter plot
plt.scatter(y_pred, residuals)
plt.xlabel('Predicted Values (Million)')
plt.ylabel('Residuals (Million)')
plt.title('Residuals vs. Predicted Values in the Training Set')
plt.grid(True, linestyle='--', alpha=0.7)
plt.axhline(y=0, color='black', linestyle='--')  # Add horizontal line at y=0 for reference
plt.show()

# # Decision Trees Test Set

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np
#Fit Regression Model

# Step 3: Make predictions on the test data
y_pred_test = dt_regressor.predict(X_test)

#Results
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Step 4: Evaluate the model's performance
dt_r2_test = r2_score(y_test, y_pred_test)
dt_mse_test = mean_squared_error(y_test, y_pred_test)
dt_rmse_test = np.sqrt(dt_mse_test)
dt_mae_test = mean_absolute_error(y_test, y_pred_test)

# Print the results
print("DT Test Set Results:")
print("R-squared (R2):", dt_r2_test)
print("Mean Squared Error (MSE):", dt_mse_test)
print("Root Mean Squared Error (RMSE):", dt_rmse_test)
print("Mean Absolute Error (MAE): ", dt_mae_test)

import matplotlib.pyplot as plt

# Assuming you already have X_test, y_test, and y_pred from your model
# If not, make sure to replace them with the correct variables

# Plot the predicted vs actual values
plt.scatter(y_test, y_pred_test, alpha=0.5, color = 'mediumseagreen')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color="red")
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Predicted vs. Actual Values")
plt.grid(True, linestyle='--', alpha=0.7)

# Show the plot
plt.show()

import matplotlib.pyplot as plt

# Calculate residuals and variance of residuals
residuals = y_test - y_pred_test
residual_variance = residuals**2

# Create a scatter plot
plt.scatter(y_pred_test, residual_variance, color = 'mediumseagreen')
plt.xlabel('Predicted Values')
plt.ylabel('Variance of Residuals')
plt.title('Variance of Residuals vs. Predicted Values')
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

import matplotlib.pyplot as plt

# Calculate residuals
residuals = y_test - y_pred_test

# Create a scatter plot
plt.scatter(y_pred_test, residuals, color = 'mediumseagreen')
plt.xlabel('Predicted Values (Million)')
plt.ylabel('Residuals (Million)')
plt.title('Residuals vs. Predicted Values in the Test Set')
plt.grid(True, linestyle='--', alpha=0.7)
plt.axhline(y=0, color='black', linestyle='--')  # Add horizontal line at y=0 for reference
plt.show()

# #Permutation Feature Importance

from sklearn.inspection import permutation_importance
r = permutation_importance(dt_regressor, X_test, y_test, 
                           n_repeats=30,
                           random_state=0)
for i in r.importances_mean.argsort()[::-1]:

        print(f"{X_test.columns[i]:<8}"
              f"{r.importances_mean[i]:.3f}"
              f" +/- {r.importances_std[i]:.3f}")

import matplotlib.pyplot as plt

# Extract the feature names, mean importances, and standard deviations
feature_names = X_test.columns
importances_mean = r.importances_mean
importances_std = r.importances_std

# Sort the features by mean importance in descending order
sorted_indices = importances_mean.argsort()[::-1]

# Create a bar plot
plt.figure(figsize=(5, 5))
plt.bar(range(len(feature_names)), importances_mean[sorted_indices], yerr=importances_std[sorted_indices], align='center')
plt.xticks(range(len(feature_names)), [feature_names[i] for i in sorted_indices], rotation=90)
#plt.xlabel('Feature')
plt.ylabel('Permutation Importance')
plt.title('PFI - DT')
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# #PDP

import numpy as np
import matplotlib.pyplot as plt

# Choose the feature of interest (e.g., 'area')
feature_to_plot = 'area'

# Generate a range of values for the feature
feature_values = np.linspace(X_test[feature_to_plot].min(), X_test[feature_to_plot].max(), num=100)

# Initialize an empty array to store the partial dependence values
pdp_values = []

# Iterate through feature values and calculate predictions
for val in feature_values:
    X_copy = X_test.copy()
    X_copy[feature_to_plot] = val
    predictions = dt_regressor.predict(X_copy)
    # Adjust the predictions to be in 1e6 notation
    pdp_values.append(predictions.mean() / 1e6)  # Expressed in Million

# Plot the PDP with price in 1e6 notation
plt.figure(figsize=(3, 5))
plt.plot(feature_values, pdp_values, marker='o', linestyle='-')
plt.title(f'PDP - DT - Area')
plt.xlabel('Area')
plt.ylabel('Price (Million)')  # Modify the y-axis label
plt.grid(True)
plt.show()







